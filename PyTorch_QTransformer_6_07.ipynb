{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOce4dy0VOI2aOb6JmX5IlG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophchoe/quantum/blob/main/PyTorch_QTransformer_6_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq torch torchvision\n",
        "!pip install -qqq pennylane\n",
        "!pip install -qqq pennylane-SF"
      ],
      "metadata": {
        "id": "tE3__8WZ868S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05f92bd-5805-46af-f2ab-8b15bc2804dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.13 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukFClVII82fH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pennylane as qml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "0rl_NmUL91Er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534afd6e-c205-4079-e567-94d0905b90f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the InputEmbedding class\n",
        "class InputEmbedding(nn.Module):\n",
        "    def __init__(self, input_vocab_size, embed_len, dropout=0.1, device='cpu'):\n",
        "        super(InputEmbedding, self).__init__()\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.embed_len = embed_len\n",
        "        self.dropout = dropout\n",
        "        self.device = device\n",
        "\n",
        "        self.firstEmbedding = nn.Embedding(self.input_vocab_size, self.embed_len).to(self.device)\n",
        "        self.secondEmbedding = nn.Embedding(self.input_vocab_size, self.embed_len).to(self.device)\n",
        "        self.dropoutLayer = nn.Dropout(p=self.dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        first_embedding = self.firstEmbedding(input).to(self.device)\n",
        "        batch_size, seq_len = input.shape\n",
        "\n",
        "        positions_vector = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n",
        "        positional_encoding = self.secondEmbedding(positions_vector).to(self.device)\n",
        "\n",
        "        return self.dropoutLayer(first_embedding + positional_encoding)"
      ],
      "metadata": {
        "id": "nDSJ2x4bOZvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_input_embedding():\n",
        "    # Define parameters\n",
        "    input_vocab_size = 100\n",
        "    embed_len = 64\n",
        "    seq_len = 10\n",
        "    batch_size = 32\n",
        "    dropout = 0.1\n",
        "    device = 'cpu'\n",
        "\n",
        "    # Create an instance of InputEmbedding\n",
        "    model = InputEmbedding(input_vocab_size, embed_len, dropout, device)\n",
        "\n",
        "    # Create a dummy input tensor with random integers in the range of the vocabulary size\n",
        "    dummy_input = torch.randint(0, input_vocab_size, (batch_size, seq_len)).to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(dummy_input)\n",
        "\n",
        "    # Check the output shape\n",
        "    assert output.shape == (batch_size, seq_len, embed_len), f\"Expected output shape {(batch_size, seq_len, embed_len)}, but got {output.shape}\"\n",
        "\n",
        "    # Check the output type\n",
        "    assert isinstance(output, torch.Tensor), f\"Expected output type torch.Tensor, but got {type(output)}\"\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "    return output.shape\n",
        "\n",
        "# Run the test\n",
        "test_input_embedding()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy17HV3EoBgu",
        "outputId": "5aed61df-883a-495f-9032-a1636ebc8ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ScaledDotProduct class\n",
        "class ScaledDotProduct(nn.Module):\n",
        "    def __init__(self, embed_len, mask=None):\n",
        "        super(ScaledDotProduct, self).__init__()\n",
        "        self.embed_len = embed_len\n",
        "        self.mask = mask\n",
        "        self.dk = embed_len  # dimension of keys and queries\n",
        "        self.softmax = nn.Softmax(dim=-1)  # Apply softmax on the last dimension\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        compatibility = torch.matmul(queries, keys.transpose(-2, -1))\n",
        "        compatibility = compatibility / math.sqrt(self.dk)\n",
        "        compatibility = self.softmax(compatibility)\n",
        "\n",
        "        if self.mask is not None:\n",
        "            compatibility = torch.tril(compatibility)\n",
        "\n",
        "        return torch.matmul(compatibility, values)"
      ],
      "metadata": {
        "id": "iFFbC2CMt2At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the ScaledDotProduct class\n",
        "def test_scaled_dot_product():\n",
        "    # Define parameters\n",
        "    embed_len = 64\n",
        "    seq_len = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    # Create an instance of ScaledDotProduct\n",
        "    model = ScaledDotProduct(embed_len)\n",
        "\n",
        "    # Create dummy input tensors\n",
        "    queries = torch.rand(batch_size, seq_len, embed_len)\n",
        "    keys = torch.rand(batch_size, seq_len, embed_len)\n",
        "    values = torch.rand(batch_size, seq_len, embed_len)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(queries, keys, values)\n",
        "\n",
        "    # Check the output shape\n",
        "    assert output.shape == (batch_size, seq_len, embed_len), f\"Expected output shape {(batch_size, seq_len, embed_len)}, but got {output.shape}\"\n",
        "\n",
        "    # Check the output type\n",
        "    assert isinstance(output, torch.Tensor), f\"Expected output type torch.Tensor, but got {type(output)}\"\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "    return output.shape\n",
        "\n",
        "# Run the test\n",
        "test_scaled_dot_product()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ2tKmtMn1L8",
        "outputId": "462b0bbf-7d10-4816-f186-aa944ba229d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MultiHeadedAttention class\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, num_heads, embed_len, batch_size, mask=None):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.embed_len = embed_len\n",
        "        self.batch_size = batch_size\n",
        "        self.mask = mask\n",
        "        self.head_length = int(self.embed_len / self.num_heads)\n",
        "        self.q_in = self.v_in = self.k_in = self.embed_len\n",
        "\n",
        "        self.q_linear = nn.Linear(int(self.q_in), int(self.q_in))\n",
        "        self.k_linear = nn.Linear(int(self.k_in), int(self.k_in))\n",
        "        self.v_linear = nn.Linear(int(self.v_in), int(self.v_in))\n",
        "\n",
        "        if self.mask is not None:\n",
        "            self.attention = ScaledDotProduct(embed_len=self.head_length, mask=True)\n",
        "        else:\n",
        "            self.attention = ScaledDotProduct(embed_len=self.head_length)\n",
        "\n",
        "        self.output_linear = nn.Linear(self.q_in, self.q_in)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        queries = self.q_linear(queries).reshape(self.batch_size, -1, self.num_heads, self.head_length)\n",
        "        queries = queries.transpose(1, 2)\n",
        "\n",
        "        keys = self.k_linear(keys).reshape(self.batch_size, -1, self.num_heads, self.head_length)\n",
        "        keys = keys.transpose(1, 2)\n",
        "\n",
        "        values = self.v_linear(values).reshape(self.batch_size, -1, self.num_heads, self.head_length)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        sdp_output = self.attention(queries, keys, values).transpose(1, 2).reshape(self.batch_size, -1, self.num_heads * self.head_length)\n",
        "\n",
        "        return self.output_linear(sdp_output)"
      ],
      "metadata": {
        "id": "KMTJfuguouem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the MultiHeadedAttention class\n",
        "def test_multi_headed_attention():\n",
        "    # Define parameters\n",
        "    num_heads = 8\n",
        "    embed_len = 64\n",
        "    seq_len = 10\n",
        "    batch_size = 32\n",
        "    mask = None\n",
        "\n",
        "    # Create an instance of MultiHeadedAttention\n",
        "    model = MultiHeadedAttention(num_heads, embed_len, batch_size, mask)\n",
        "\n",
        "    # Create dummy input tensors\n",
        "    queries = torch.rand(batch_size, seq_len, embed_len)\n",
        "    keys = torch.rand(batch_size, seq_len, embed_len)\n",
        "    values = torch.rand(batch_size, seq_len, embed_len)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(queries, keys, values)\n",
        "\n",
        "    # Check the output shape\n",
        "    assert output.shape == (batch_size, seq_len, embed_len), f\"Expected output shape {(batch_size, seq_len, embed_len)}, but got {output.shape}\"\n",
        "\n",
        "    # Check the output type\n",
        "    assert isinstance(output, torch.Tensor), f\"Expected output type torch.Tensor, but got {type(output)}\"\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "    return output.shape\n",
        "\n",
        "# Run the test\n",
        "test_multi_headed_attention()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ZFe2W7yzpF",
        "outputId": "396ef489-e93a-468b-a834-ba939148fc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataEncoding class\n",
        "class DataEncoding:\n",
        "    def __init__(self, num_wires):\n",
        "        self.num_wires = num_wires\n",
        "\n",
        "    def encode(self, x):\n",
        "        num_features = len(x)\n",
        "\n",
        "        # Squeezing gates\n",
        "        for i in range(0, min(num_features, self.num_wires * 2), 2):\n",
        "            qml.Squeezing(x[i], x[i + 1], wires=i // 2)\n",
        "\n",
        "        # Beamsplitter gates\n",
        "        for i in range(self.num_wires - 1):\n",
        "            idx = self.num_wires * 2 + i * 2\n",
        "            if idx + 1 < num_features:\n",
        "                qml.Beamsplitter(x[idx], x[idx + 1], wires=[i % self.num_wires, (i + 1) % self.num_wires])\n",
        "\n",
        "        # Rotation gates\n",
        "        for i in range(self.num_wires):\n",
        "            idx = self.num_wires * 2 + (self.num_wires - 1) * 2 + i\n",
        "            if idx < num_features:\n",
        "                qml.Rotation(x[idx], wires=i)\n",
        "\n",
        "        # Displacement gates\n",
        "        for i in range(self.num_wires):\n",
        "            idx = self.num_wires * 2 + (self.num_wires - 1) * 2 + self.num_wires + i * 2\n",
        "            if idx + 1 < num_features:\n",
        "                qml.Displacement(x[idx], x[idx + 1], wires=i)\n",
        "\n",
        "        # Kerr gates\n",
        "        for i in range(self.num_wires):\n",
        "            idx = self.num_wires * 2 + (self.num_wires - 1) * 2 + self.num_wires + self.num_wires * 2 + i\n",
        "            if idx < num_features:\n",
        "                qml.Kerr(x[idx], wires=i)\n",
        "\n",
        "        # Squeezing gates (second set)\n",
        "        for i in range(0, min(num_features - (self.num_wires * 2 + (self.num_wires - 1) * 2 + self.num_wires + self.num_wires * 2 + self.num_wires), self.num_wires * 2), 2):\n",
        "            idx = self.num_wires * 2 + (self.num_wires - 1) * 2 + self.num_wires + self.num_wires * 2 + self.num_wires + i\n",
        "            if idx + 1 < num_features:\n",
        "                qml.Squeezing(x[idx], x[idx + 1], wires=i // 2)\n",
        "\n",
        "        # Rotation gates (second set)\n",
        "        for i in range(self.num_wires):\n",
        "            idx = self.num_wires * 2 + (self.num_wires - 1) * 2 + self.num_wires + self.num_wires * 2 + self.num_wires + self.num_wires * 2 + i\n",
        "            if idx < num_features:\n",
        "                qml.Rotation(x[idx], wires=i)\n",
        "\n",
        "# Define the QuantumLayer class\n",
        "class QuantumLayer:\n",
        "    def __init__(self, num_wires):\n",
        "        self.num_wires = num_wires\n",
        "\n",
        "    def apply_layer(self, v):\n",
        "        num_params = len(v)\n",
        "\n",
        "        # Interferometer 1\n",
        "        for i in range(self.num_wires - 1):\n",
        "            idx = i * 2\n",
        "            if idx + 1 < num_params:\n",
        "                theta = v[idx]\n",
        "                phi = v[idx + 1]\n",
        "                qml.Beamsplitter(theta, phi, wires=[i % self.num_wires, (i + 1) % self.num_wires])\n",
        "\n",
        "        for i in range(self.num_wires):\n",
        "            idx = (self.num_wires - 1) * 2 + i\n",
        "            if idx < num_params:\n",
        "                qml.Rotation(v[idx], wires=i)\n",
        "\n",
        "        # Squeezers\n",
        "        for i in range(self.num_wires):\n",
        "            idx = (self.num_wires - 1) * 2 + self.num_wires + i\n",
        "            if idx < num_params:\n",
        "                qml.Squeezing(v[idx], 0.0, wires=i)\n",
        "\n",
        "        # Interferometer 2\n",
        "        for i in range(self.num_wires - 1):\n",
        "            idx = (self.num_wires - 1) * 2 + self.num_wires + self.num_wires + i * 2\n",
        "            if idx + 1 < num_params:\n",
        "                theta = v[idx]\n",
        "                phi = v[idx + 1]\n",
        "                qml.Beamsplitter(theta, phi, wires=[i % self.num_wires, (i + 1) % self.num_wires])\n",
        "\n",
        "        for i in range(self.num_wires):\n",
        "            idx = (self.num_wires - 1) * 2 + self.num_wires + self.num_wires + (self.num_wires - 1) * 2 + i\n",
        "            if idx < num_params:\n",
        "                qml.Rotation(v[idx], wires=i)\n",
        "\n",
        "        # Bias addition\n",
        "        for i in range(self.num_wires):\n",
        "            idx = (self.num_wires - 1) * 2 + self.num_wires + self.num_wires + (self.num_wires - 1) * 2 + self.num_wires + i\n",
        "            if idx < num_params:\n",
        "                qml.Displacement(v[idx], 0.0, wires=i)\n",
        "\n",
        "        # Non-linear activation function\n",
        "        for i in range(self.num_wires):\n",
        "            idx = (self.num_wires - 1) * 2 + self.num_wires + self.num_wires + (self.num_wires - 1) * 2 + self.num_wires + self.num_wires + i\n",
        "            if idx < num_params:\n",
        "                qml.Kerr(v[idx], wires=i)\n",
        "\n",
        "# Define the WeightInitializer class\n",
        "class WeightInitializer:\n",
        "    @staticmethod\n",
        "    def init_weights(layers, modes, active_sd=0.0001, passive_sd=0.1):\n",
        "        M = (modes - 1) * 2 + modes  # Number of interferometer parameters\n",
        "\n",
        "        int1_weights = np.random.normal(size=[layers, M], scale=passive_sd)\n",
        "        s_weights = np.random.normal(size=[layers, modes], scale=active_sd)\n",
        "        int2_weights = np.random.normal(size=[layers, M], scale=passive_sd)\n",
        "        dr_weights = np.random.normal(size=[layers, modes], scale=active_sd)\n",
        "        k_weights = np.random.normal(size=[layers, modes], scale=active_sd)\n",
        "\n",
        "        weights = np.concatenate([int1_weights, s_weights, int2_weights, dr_weights, k_weights], axis=1)\n",
        "\n",
        "        return weights\n",
        "\n",
        "# Think through the output\n",
        "num_modes = 6\n",
        "num_basis = 2\n",
        "\n",
        "# Select a device\n",
        "dev = qml.device(\"strawberryfields.fock\", wires=num_modes, cutoff_dim=num_basis)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_nn(inputs, var):\n",
        "    num_wires = 6\n",
        "    encoder = DataEncoding(num_wires)\n",
        "    encoder.encode(inputs)\n",
        "\n",
        "    # Iterative quantum layers\n",
        "    q_layer = QuantumLayer(num_wires)\n",
        "    for v in var:\n",
        "        q_layer.apply_layer(v)\n",
        "\n",
        "    # Return the probabilities\n",
        "    return qml.probs(wires=[0, 1, 2, 3, 4, 5])\n",
        "\n",
        "num_layers = 2\n",
        "\n",
        "# Initialize weights for quantum layers\n",
        "weights = WeightInitializer.init_weights(num_layers, num_modes)\n",
        "\n",
        "# Convert the quantum layer to a Torch layer\n",
        "shape_tup = weights.shape\n",
        "weight_shapes = {'var': shape_tup}\n",
        "\n",
        "qlayer = qml.qnn.TorchLayer(quantum_nn, weight_shapes)\n",
        "layers = [qlayer]\n",
        "\n",
        "# Define the FeedForwardBlock class\n",
        "class QuantumFeedForwardBlock(nn.Module):\n",
        "    def __init__(self, embed_len, dropout=0.1):\n",
        "        super(QuantumFeedForwardBlock, self).__init__()\n",
        "        self.feed_forward = nn.Sequential(*layers)\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.layer_norm = nn.LayerNorm(embed_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ff_output = self.feed_forward(x)\n",
        "        ff_output = self.dropout_layer(ff_output)\n",
        "        return self.layer_norm(ff_output + x)\n"
      ],
      "metadata": {
        "id": "DfJAJdXTnyLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "embed_len = 64  # example value\n",
        "model = QuantumFeedForwardBlock(embed_len)\n",
        "\n",
        "# Calculate the number of parameters\n",
        "def count_parameters(module):\n",
        "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f'Total number of parameters in FeedForwardBlock: {total_params}')"
      ],
      "metadata": {
        "id": "3wnR5rJM0aKO",
        "outputId": "9fca0f6e-10cd-41ee-ec56-bdbe89bb1de7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in FeedForwardBlock: 228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the QuantumFeedForwardBlock class\n",
        "def test_quantum_feed_forward_block():\n",
        "    # Define parameters\n",
        "    embed_len = 64\n",
        "    seq_len = 10\n",
        "    batch_size = 32\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Create an instance of FeedForwardBlock\n",
        "    model = QuantumFeedForwardBlock(embed_len, dropout)\n",
        "\n",
        "    # Create a dummy input tensor\n",
        "    dummy_input = torch.rand(batch_size, seq_len, embed_len)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(dummy_input)\n",
        "\n",
        "    # Check the output shape\n",
        "    assert output.shape == (batch_size, seq_len, embed_len), f\"Expected output shape {(batch_size, seq_len, embed_len)}, but got {output.shape}\"\n",
        "\n",
        "    # Check the output type\n",
        "    assert isinstance(output, torch.Tensor), f\"Expected output type torch.Tensor, but got {type(output)}\"\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "    return output.shape\n",
        "\n",
        "# Run the test\n",
        "test_quantum_feed_forward_block()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY0OgbO6o9ru",
        "outputId": "5f70c525-7041-44c4-9eb8-52644f525bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the EncoderBlock class\n",
        "class QuantumEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_len, num_heads, batch_size, dropout=0.1, mask=None):\n",
        "        super(QuantumEncoderBlock, self).__init__()\n",
        "        self.embed_len = embed_len\n",
        "        self.multihead = MultiHeadedAttention(num_heads, embed_len, batch_size, mask)\n",
        "        self.first_norm = nn.LayerNorm(self.embed_len)\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.quantum_feed_forward_block = QuantumFeedForwardBlock(embed_len, dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        attention_output = self.multihead(queries, keys, values)\n",
        "        attention_output = self.dropout_layer(attention_output)\n",
        "        first_sublayer_output = self.first_norm(attention_output + queries)\n",
        "        return self.quantum_feed_forward_block(first_sublayer_output)"
      ],
      "metadata": {
        "id": "aQEa3bopyxmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the EncoderBlock class\n",
        "def test_quantum_encoder_block():\n",
        "    # Define parameters\n",
        "    embed_len = 64\n",
        "    num_heads = 8\n",
        "    seq_len = 10\n",
        "    batch_size = 32\n",
        "    dropout = 0.1\n",
        "    mask = None\n",
        "\n",
        "    # Create an instance of EncoderBlock\n",
        "    model = QuantumEncoderBlock(embed_len, num_heads, batch_size, dropout, mask)\n",
        "\n",
        "    # Create dummy input tensors\n",
        "    queries = torch.rand(batch_size, seq_len, embed_len)\n",
        "    keys = torch.rand(batch_size, seq_len, embed_len)\n",
        "    values = torch.rand(batch_size, seq_len, embed_len)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(queries, keys, values)\n",
        "\n",
        "    # Check the output shape\n",
        "    assert output.shape == (batch_size, seq_len, embed_len), f\"Expected output shape {(batch_size, seq_len, embed_len)}, but got {output.shape}\"\n",
        "\n",
        "    # Check the output type\n",
        "    assert isinstance(output, torch.Tensor), f\"Expected output type torch.Tensor, but got {type(output)}\"\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "    return output.shape\n",
        "\n",
        "# Run the test\n",
        "test_quantum_encoder_block()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUPUpKtIpY_n",
        "outputId": "54ad6edd-d820-4b8f-fd13-de75f22fc7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DecoderBlock class\n",
        "class QuantumDecoderBlock(nn.Module):\n",
        "    def __init__(self, embed_len, num_heads, batch_size, dropout=0.1, mask=None):\n",
        "        super(QuantumDecoderBlock, self).__init__()\n",
        "        self.embed_len = embed_len\n",
        "        self.multihead_self_attention = MultiHeadedAttention(num_heads, embed_len, batch_size, mask)\n",
        "        self.multihead_enc_dec_attention = MultiHeadedAttention(num_heads, embed_len, batch_size, mask)\n",
        "        self.first_norm = nn.LayerNorm(self.embed_len)\n",
        "        self.second_norm = nn.LayerNorm(self.embed_len)\n",
        "        self.third_norm = nn.LayerNorm(self.embed_len)\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.quantum_feed_forward_block = QuantumFeedForwardBlock(embed_len, dropout)\n",
        "\n",
        "    def forward(self, target, encoder_output):\n",
        "        # Self attention\n",
        "        self_attention_output = self.multihead_self_attention(target, target, target)\n",
        "        self_attention_output = self.dropout_layer(self_attention_output)\n",
        "        first_sublayer_output = self.first_norm(self_attention_output + target)\n",
        "\n",
        "        # Encoder-decoder attention\n",
        "        enc_dec_attention_output = self.multihead_enc_dec_attention(first_sublayer_output, encoder_output, encoder_output)\n",
        "        enc_dec_attention_output = self.dropout_layer(enc_dec_attention_output)\n",
        "        second_sublayer_output = self.second_norm(enc_dec_attention_output + first_sublayer_output)\n",
        "\n",
        "        # Feed-forward\n",
        "        return self.quantum_feed_forward_block(second_sublayer_output)"
      ],
      "metadata": {
        "id": "ul0TBgnnOt5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the DecoderBlock class\n",
        "def test_quantum_decoder_block():\n",
        "    # Define parameters\n",
        "    embed_len = 64\n",
        "    num_heads = 8\n",
        "    seq_len = 10\n",
        "    batch_size = 32\n",
        "    dropout = 0.1\n",
        "    mask = None\n",
        "\n",
        "    # Create an instance of DecoderBlock\n",
        "    model = QuantumDecoderBlock(embed_len, num_heads, batch_size, dropout, mask)\n",
        "\n",
        "    # Create dummy input tensors\n",
        "    target = torch.rand(batch_size, seq_len, embed_len)\n",
        "    encoder_output = torch.rand(batch_size, seq_len, embed_len)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(target, encoder_output)\n",
        "\n",
        "    # Check the output shape\n",
        "    assert output.shape == (batch_size, seq_len, embed_len), f\"Expected output shape {(batch_size, seq_len, embed_len)}, but got {output.shape}\"\n",
        "\n",
        "    # Check the output type\n",
        "    assert isinstance(output, torch.Tensor), f\"Expected output type torch.Tensor, but got {type(output)}\"\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "    return output.shape\n",
        "\n",
        "# Run the test\n",
        "test_quantum_decoder_block()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVIsGLZ3s9DX",
        "outputId": "4725a342-1ea0-421b-8ba0-bedb67bf95ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Transformer class\n",
        "# Change the out_linear to quantum\n",
        "class QuantumTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers, num_decoder_layers, embed_len, num_heads, batch_size, vocab_size, dropout=0.1, device='cpu'):\n",
        "        super(QuantumTransformer, self).__init__()\n",
        "        self.embed_len = embed_len\n",
        "        self.device = device\n",
        "        self.embedding = InputEmbedding(vocab_size, embed_len, dropout, device).to(device)\n",
        "        self.encoder_layers = nn.ModuleList([QuantumEncoderBlock(embed_len, num_heads, batch_size, dropout).to(device) for _ in range(num_encoder_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([QuantumDecoderBlock(embed_len, num_heads, batch_size, dropout).to(device) for _ in range(num_decoder_layers)])\n",
        "        self.output_linear = nn.Linear(embed_len, vocab_size).to(device)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_embedded = self.embedding(src)\n",
        "        tgt_embedded = self.embedding(tgt)\n",
        "\n",
        "        # Encoder forward pass\n",
        "        encoder_output = src_embedded\n",
        "        for layer in self.encoder_layers:\n",
        "            encoder_output = layer(encoder_output, encoder_output, encoder_output)\n",
        "\n",
        "        # Decoder forward pass\n",
        "        decoder_output = tgt_embedded\n",
        "        for layer in self.decoder_layers:\n",
        "            decoder_output = layer(decoder_output, encoder_output)\n",
        "\n",
        "        return self.output_linear(decoder_output)"
      ],
      "metadata": {
        "id": "I66kyuLWzsWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Transformer class\n",
        "def test_quantum_transformer():\n",
        "    # Define parameters\n",
        "    num_encoder_layers = 6\n",
        "    num_decoder_layers = 6\n",
        "    embed_len = 64\n",
        "    num_heads = 8\n",
        "    seq_len = 20\n",
        "    batch_size = 32\n",
        "    vocab_size = 100\n",
        "    dropout = 0.1\n",
        "    device = 'cpu'\n",
        "\n",
        "    # Create an instance of Transformer\n",
        "    model = QuantumTransformer(num_encoder_layers, num_decoder_layers, embed_len, num_heads, batch_size, vocab_size, dropout, device)\n",
        "\n",
        "    # Create dummy input tensors\n",
        "    src = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
        "    tgt = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(src, tgt)\n",
        "\n",
        "    # Check the output shape\n",
        "    assert output.shape == (batch_size, seq_len, vocab_size), f\"Expected output shape {(batch_size, seq_len, vocab_size)}, but got {output.shape}\"\n",
        "\n",
        "    # Check the output type\n",
        "    assert isinstance(output, torch.Tensor), f\"Expected output type torch.Tensor, but got {type(output)}\"\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "    return output.shape\n",
        "\n",
        "# Run the test\n",
        "test_quantum_transformer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2giU6VWhtc_Y",
        "outputId": "bf9212b6-51cc-4b0a-9b34-9d9b42674388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 20, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee9Et2jtxcbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWBtl6qWDFG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}